{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates how to run audio-visual speech separation (AVSS) inference using our pretrained RTFS-Net model.\n",
        "\n",
        "Project code and description: https://github.com/avsshw/AVSS"
      ],
      "metadata": {
        "id": "70X1Nnldhzab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "4CQfDLrBbEiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, clone the repository:"
      ],
      "metadata": {
        "id": "DJnoCawJiBiO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BWaErhOU1Vuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de2cd86-bbd7-4d03-cbbc-26640dce6d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AVSS'...\n",
            "remote: Enumerating objects: 417, done.\u001b[K\n",
            "remote: Counting objects: 100% (417/417), done.\u001b[K\n",
            "remote: Compressing objects: 100% (264/264), done.\u001b[K\n",
            "remote: Total 417 (delta 214), reused 319 (delta 142), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (417/417), 1.52 MiB | 31.68 MiB/s, done.\n",
            "Resolving deltas: 100% (214/214), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/avsshw/AVSS.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AVSS"
      ],
      "metadata": {
        "id": "Ua0RqhLO1grP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080acaed-8b45-4c6d-8c7d-badfc3297daf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AVSS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "7_PSL6Rc1it3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We trained our model on the dataset of the following format:\n",
        "\n",
        "\n",
        "```bash\n",
        "NameOfTheDirectoryWithUtterances/\n",
        "├── audio/\n",
        "│   ├── train/\n",
        "│   │   ├── mix/          # Mixed audio utterances (2-speaker mixtures)\n",
        "│   │   ├── s1/          \n",
        "│   │   └── s2/          \n",
        "│   └── val/\n",
        "│       ├── mix/\n",
        "│       ├── s1/\n",
        "│       └── s2/\n",
        "└── mouths/\n",
        "    ├── train/            \n",
        "    │   ├── SpeakerID1.npz\n",
        "    │   ├── SpeakerID2.npz\n",
        "    │   └── ...\n",
        "    └── val/\n",
        "        ├── SpeakerID1.npz\n",
        "        ├── SpeakerID2.npz\n",
        "        └── ...\n",
        "```"
      ],
      "metadata": {
        "id": "kmFKLUGXXZx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be evaluated with the following commands which you can follow if needed:\n",
        "\n",
        "1.\n",
        "```bash\n",
        "gdown https://drive.google.com/uc?id=1t7FFsG3hPcgUYuitekSMpggYLvzV6SXW\n",
        "unzip /content/AVSS-main/rtfs.zip\n",
        "```\n",
        "\n",
        "2. Assuming you have dla_dataset directory in the root of the project (or you can change it via hydra option datasets.test.data_dir=your/dataset):\n",
        "```bash\n",
        "python3 inference.py inferencer.from_pretrained=rtfs_improved/model_best.pth datasets=val_inference\n",
        "```"
      ],
      "metadata": {
        "id": "7w_1MXgGabBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1t7FFsG3hPcgUYuitekSMpggYLvzV6SXW\n",
        "!unzip /content/AVSS/rtfs.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSl4MJB60Wyw",
        "outputId": "8064fea2-dc64-42fd-aefc-06088631cf25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1t7FFsG3hPcgUYuitekSMpggYLvzV6SXW\n",
            "From (redirected): https://drive.google.com/uc?id=1t7FFsG3hPcgUYuitekSMpggYLvzV6SXW&confirm=t&uuid=c3a1b020-9c9c-4c5c-a945-e92be7beacae\n",
            "To: /content/AVSS/rtfs.zip\n",
            "100% 311M/311M [00:00<00:00, 366MB/s]\n",
            "Archive:  /content/AVSS/rtfs.zip\n",
            "   creating: rtfs_improved/\n",
            "  inflating: rtfs_improved/checkpoint-epoch80.pth  \n",
            "  inflating: rtfs_improved/config.yaml  \n",
            "  inflating: rtfs_improved/checkpoint-epoch110.pth  \n",
            "  inflating: rtfs_improved/info.log  \n",
            "  inflating: rtfs_improved/checkpoint-epoch20.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch60.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch120.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch190.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch150.pth  \n",
            "  inflating: rtfs_improved/git_diff.patch  \n",
            "  inflating: rtfs_improved/checkpoint-epoch170.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch10.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch200.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch30.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch90.pth  \n",
            " extracting: rtfs_improved/git_commit.txt  \n",
            "  inflating: rtfs_improved/checkpoint-epoch160.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch130.pth  \n",
            "  inflating: rtfs_improved/checkpoint-epoch140.pth  \n",
            "  inflating: rtfs_improved/model_best.pth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "!HYDRA_FULL_ERROR=1 uv run python3 inference.py \\\n",
        "  datasets.test.data_dir=inference_dataset \\\n",
        "  inferencer.from_pretrained=rtfs_improved/model_best.pth \\\n",
        "  datasets=custom_dir"
      ],
      "metadata": {
        "id": "-R6kcFpxxWay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb51457-c463-4edf-9f09-0461e8e5ccca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPython \u001b[36m3.12.11\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m113 packages\u001b[0m \u001b[2min 908ms\u001b[0m\u001b[0m\n",
            "RTFSNet(\n",
            "  (encoder): STFT()\n",
            "  (decoder): ISTFT()\n",
            "  (blocks): ModuleList(\n",
            "    (0): RTFSBlock(\n",
            "      (input_proj): Linear(in_features=2, out_features=64, bias=True)\n",
            "      (freq_rnn): FrequencyRNN(\n",
            "        (rnn): LSTM(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (time_rnn): TimeRNN(\n",
            "        (rnn): LSTM(128, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (tf_interaction): TFInteraction(\n",
            "        (freq_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (time_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffn): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "        )\n",
            "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (output_proj): Linear(in_features=128, out_features=64, bias=True)\n",
            "    )\n",
            "    (1-3): 3 x RTFSBlock(\n",
            "      (input_proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (freq_rnn): FrequencyRNN(\n",
            "        (rnn): LSTM(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (time_rnn): TimeRNN(\n",
            "        (rnn): LSTM(128, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (tf_interaction): TFInteraction(\n",
            "        (freq_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (time_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffn): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "        )\n",
            "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (output_proj): Linear(in_features=128, out_features=64, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (mask_estimator): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=4, bias=True)\n",
            "    (3): Tanh()\n",
            "  )\n",
            ")\n",
            "Loading model weights from: rtfs_improved/model_best.pth ...\n",
            "test: 100% 3/3 [00:03<00:00,  1.26s/it]\n",
            "    test_SI-SNRi   : 12.02201239267985\n",
            "    test_SDRi      : 12.440301577250162\n",
            "    test_PESQ      : 2.0738654931386313\n",
            "    test_STOI      : 0.8945748607317606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfYc4R8O1Z8y",
        "outputId": "9dfd85fa-afcf-452e-821b-be7a59362c1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inference_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom inference"
      ],
      "metadata": {
        "id": "S4UTBE0rbr1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you wish to run inference on your custom dataset, our model expects data in the following structure:\n",
        "\n",
        "\n",
        "```bash\n",
        "NameOfTheDirectoryWithUtterances\n",
        "├── audio\n",
        "│   ├── mix\n",
        "│   │   ├── FirstSpeakerID1_SecondSpeakerID1.wav # also may be flac or mp3\n",
        "│   │   ├── FirstSpeakerID2_SecondSpeakerID2.wav\n",
        "│   │   .\n",
        "│   │   .\n",
        "│   │   .\n",
        "│   │   └── FirstSpeakerIDn_SecondSpeakerIDn.wav\n",
        "│   ├── s1 # ground truth for the speaker s1, may not be given\n",
        "│   │   ├── FirstSpeakerID1_SecondSpeakerID1.wav # also may be flac or mp3\n",
        "│   │   ├── FirstSpeakerID2_SecondSpeakerID2.wav\n",
        "│   │   .\n",
        "│   │   .\n",
        "│   │   .\n",
        "│   │   └── FirstSpeakerIDn_SecondSpeakerIDn.wav\n",
        "│   └── s2 # ground truth for the speaker s2, may not be given\n",
        "│       ├── FirstSpeakerID1_SecondSpeakerID1.wav # also may be flac or mp3\n",
        "│       ├── FirstSpeakerID2_SecondSpeakerID2.wav\n",
        "│       .\n",
        "│       .\n",
        "│       .\n",
        "│       └── FirstSpeakerIDn_SecondSpeakerIDn.wav\n",
        "└── mouths # contains video information for all speakers\n",
        "    ├── FirstOrSecondSpeakerID1.npz # npz mouth-crop\n",
        "    ├── FirstOrSecondSpeakerID2.npz\n",
        "    .\n",
        "    .\n",
        "    .\n",
        "    └── FirstOrSecondSpeakerIDn.npz\n",
        "```"
      ],
      "metadata": {
        "id": "WtmD-ubJ13ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We provide a small example dataset with ground truths. To run inference:**"
      ],
      "metadata": {
        "id": "WnBlDTEcbIuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download the data (you can pass the link to your YandexDisk dataset in the .zip format here):"
      ],
      "metadata": {
        "id": "FtauQ46BbMmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uv run python3 scripts/download_inference_data.py --link https://disk.yandex.ru/d/h2t8ItWMdne2ZA --download_location ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwePmLjI3KFV",
        "outputId": "89bb7882-958d-4f8d-b66a-0b3a66f862f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete.\n",
            "Extracting ./inference_dataset.zip...\n",
            "Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our example dataset you can also use\n",
        "```bash\n",
        "sh scripts/inference.sh\n",
        "```\n",
        "\n",
        "but we provide you with a full comand for your own use above."
      ],
      "metadata": {
        "id": "KfCgo9pMj3FI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Download the pretrained model:"
      ],
      "metadata": {
        "id": "Z4IhED4Piooi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1l72LuBr_CQxaut6WUbyyPFJIRIbH8-68\n",
        "!unzip /content/AVSS/rtfs.zip"
      ],
      "metadata": {
        "id": "JtXExN3c4T2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7787330b-d55e-47bd-8583-7796bd2c34e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l72LuBr_CQxaut6WUbyyPFJIRIbH8-68\n",
            "From (redirected): https://drive.google.com/uc?id=1l72LuBr_CQxaut6WUbyyPFJIRIbH8-68&confirm=t&uuid=a2586278-e167-4389-94cc-5a7f9ccd3421\n",
            "To: /content/AVSS/rtfs.zip\n",
            "100% 311M/311M [00:03<00:00, 89.9MB/s]\n",
            "Archive:  /content/AVSS/rtfs.zip\n",
            "replace rtfs_improved/checkpoint-epoch80.pth? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Set environment & run inference:\n",
        "\n",
        "(Predictions will be saved to data/saved/inference_custom_dir/test, works even if you don't have ground truth like we do)"
      ],
      "metadata": {
        "id": "-vmWUYpqitMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "!sh scripts/inference.sh"
      ],
      "metadata": {
        "id": "lSyxCZgA118h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60902ff9-9f08-4acd-8462-c37821bdad28"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RTFSNet(\n",
            "  (encoder): STFT()\n",
            "  (decoder): ISTFT()\n",
            "  (blocks): ModuleList(\n",
            "    (0): RTFSBlock(\n",
            "      (input_proj): Linear(in_features=2, out_features=64, bias=True)\n",
            "      (freq_rnn): FrequencyRNN(\n",
            "        (rnn): LSTM(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (time_rnn): TimeRNN(\n",
            "        (rnn): LSTM(128, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (tf_interaction): TFInteraction(\n",
            "        (freq_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (time_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffn): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "        )\n",
            "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (output_proj): Linear(in_features=128, out_features=64, bias=True)\n",
            "    )\n",
            "    (1-3): 3 x RTFSBlock(\n",
            "      (input_proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (freq_rnn): FrequencyRNN(\n",
            "        (rnn): LSTM(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (time_rnn): TimeRNN(\n",
            "        (rnn): LSTM(128, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (tf_interaction): TFInteraction(\n",
            "        (freq_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (time_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffn): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "        )\n",
            "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (output_proj): Linear(in_features=128, out_features=64, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (mask_estimator): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=4, bias=True)\n",
            "    (3): Tanh()\n",
            "  )\n",
            ")\n",
            "Loading model weights from: rtfs_improved/model_best.pth ...\n",
            "test: 100% 3/3 [00:03<00:00,  1.02s/it]\n",
            "    test_SI-SNRi   : 12.02201239267985\n",
            "    test_SDRi      : 12.440301577250162\n",
            "    test_PESQ      : 2.0738654931386313\n",
            "    test_STOI      : 0.8945748607317606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your dataset folder is named something other than \"inference_dataset\",\n",
        "run full version of command where you can specify your dataset name.\n",
        "\n",
        "```bash\n",
        "import os\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "!uv run python3 inference.py \\\n",
        "    datasets.test.data_dir=YOUR_DATASET_NAME \\\n",
        "    inferencer.from_pretrained=rtfs_improved/model_best.pth \\\n",
        "    datasets=custom_dir\n",
        "```"
      ],
      "metadata": {
        "id": "x0AheTOba_-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "!uv run python3 inference.py \\\n",
        "    datasets.test.data_dir=inference_dataset \\\n",
        "    inferencer.from_pretrained=rtfs_improved/model_best.pth \\\n",
        "    datasets=custom_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzyU3DR0D_-M",
        "outputId": "211d995e-1811-4015-e1b3-2634158069d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RTFSNet(\n",
            "  (encoder): STFT()\n",
            "  (decoder): ISTFT()\n",
            "  (blocks): ModuleList(\n",
            "    (0): RTFSBlock(\n",
            "      (input_proj): Linear(in_features=2, out_features=64, bias=True)\n",
            "      (freq_rnn): FrequencyRNN(\n",
            "        (rnn): LSTM(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (time_rnn): TimeRNN(\n",
            "        (rnn): LSTM(128, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (tf_interaction): TFInteraction(\n",
            "        (freq_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (time_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffn): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "        )\n",
            "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (output_proj): Linear(in_features=128, out_features=64, bias=True)\n",
            "    )\n",
            "    (1-3): 3 x RTFSBlock(\n",
            "      (input_proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (freq_rnn): FrequencyRNN(\n",
            "        (rnn): LSTM(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (time_rnn): TimeRNN(\n",
            "        (rnn): LSTM(128, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (tf_interaction): TFInteraction(\n",
            "        (freq_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (time_conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffn): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "        )\n",
            "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (output_proj): Linear(in_features=128, out_features=64, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (mask_estimator): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=4, bias=True)\n",
            "    (3): Tanh()\n",
            "  )\n",
            ")\n",
            "Loading model weights from: rtfs_improved/model_best.pth ...\n",
            "test: 100% 3/3 [00:02<00:00,  1.27it/s]\n",
            "    test_SI-SNRi   : 12.02201239267985\n",
            "    test_SDRi      : 12.440301577250162\n",
            "    test_PESQ      : 2.0738654931386313\n",
            "    test_STOI      : 0.8945748607317606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Evaluate metrics (Optional)"
      ],
      "metadata": {
        "id": "l84ZXI5_cPbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your dataset includes ground-truth clean sources (s1/, s2/), you can compute metrics separately:"
      ],
      "metadata": {
        "id": "4nU0LUY8gPFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "!uv run python3 calc_metrics.py \\\n",
        "--predictions_dir data/saved/inference_custom_dir/test \\\n",
        "--ground_truth_dir inference_dataset/audio \\\n",
        "--mixture_dir inference_dataset/audio/mix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kebOdzE-f38K",
        "outputId": "acc2ca13-ee57-4879-c50a-23f39b47c40c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 3/3 [00:01<00:00,  1.53it/s]\n",
            "SI-SNRi        : 12.0220\n",
            "SDRi           : 12.4403\n",
            "PESQ           : 2.0737\n",
            "STOI           : 0.8946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script assumes:\n",
        "\n",
        "Predictions are .wav files with the same names as mixtures.\n",
        "\n",
        "(by default they are saved in data/saved/inference_custom_dir/test)\n",
        "\n",
        "Ground truth is split into s1/ and s2/ subdirectories.\n",
        "\n",
        "Mixtures are in mixture_dir."
      ],
      "metadata": {
        "id": "9ExptSgTi_Bf"
      }
    }
  ]
}